{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Dataset use cases\n",
    "*basics*\n",
    "- Upload dataset\n",
    "- Upload annotations\n",
    "\n",
    "*advanced*\n",
    "- prepare data for training\n",
    "- explore annotations\n",
    "- manage annotations\n",
    "- explore predictions\n",
    "\n",
    "**prepare data for training**\n",
    "- get data in right format for pytorch, tf\n",
    "- augment data\n",
    "- split images\n",
    "- train / test split\n",
    "\n",
    "**explore annotations**\n",
    "- see images with certain classes\n",
    "- see objects with certain classes\n",
    "- see statistics about annotations\n",
    "\n",
    "**manage annotations**\n",
    "- rename classes\n",
    "- compare annotation sets\n",
    "\n",
    "**explore predictions**\n",
    "- upload predictions\n",
    "- see model performance\n",
    "- see confusion matrix\n",
    "- categorise predictions: confusion matrix\n",
    "\n",
    "\n",
    "*prepare data for training - methods*\n",
    "1. data_handle = Dataset.prepare_data(\"pytorch\")\n",
    "\n",
    "Later: \n",
    "2. Dataset.augment_data() # use albumentation\n",
    "3. Dataset.get_data(\"train\")\n",
    "\n",
    "\n",
    "*explore annotations - methods*\n",
    "1. Dataset -> have a default annotation set associated with it\n",
    "2. Dataset.get_images(class, tag)\n",
    "3. Dataset.show_images(class, tag)\n",
    "4. Dataset.show_objects(class, tag)\n",
    "5. Dataset.annotation_statistcs()\n",
    "\n",
    "*manage annotations - methods*\n",
    "\n",
    "1. Dataset.rename_class()\n",
    "2. Dataset.compare_annotations(annotation_sets = [], prediction_sets = [])\n",
    "\n",
    "*explore predictions - methods*\n",
    "Later? \n",
    "1. Dataset.upload_predictions()\n",
    "2. Dataset.model_performance() # depending on the task. User can upload custom metrics / set defaults.\n",
    "3. Dataset.confusion_matrix()\n",
    "4. Dataset.view_predictions(true_class = \"all\", predicted_class = \"all\", only_errors = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import remo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did it ask to login?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdk = remo.SDK('https://remo.ai', 'email_address', 'password')\n",
    "\n",
    "dataset = sdk.create_dataset('Demo2: imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open https://remo.ai/datasets/13\n"
     ]
    }
   ],
   "source": [
    "dataset.upload(urls=[\"https://remo-sample-datasets.s3-eu-west-1.amazonaws.com/Imagenet_sample_dataset.zip\"],\n",
    "               annotation_task=remo.AnnotationTask.image_classification)\n",
    "\n",
    "dataset.browse()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fetch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No annotation sets in dataset Demo2: imagenet\n"
     ]
    }
   ],
   "source": [
    "dataset.annotate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption for now: Data needs to be in the same machine as we are training a model.\n",
    "- If it is already, good.\n",
    "- Otherwise, it needs to be downloaded.\n",
    "\n",
    "In future: look to stream data from somewhere to the machines that need to do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handle = Dataset.prepare_data(\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
